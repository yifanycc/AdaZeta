# Source code for paper AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning

## Submitting to EMNLP 24

## How to run this code?
- Install the conda environment with the provided environment.yml file, the environment is mainly base on torch==2.3.0 and transformers==4.40.0
- Run the shell script run_all_large_exp.sh in the large_models_experiments folder